# Metagenome Hybrid Assembly with Cerulean
by Tessa Rhinehart (contact: tessa.rhinehart at gmail dot com)

This notebook walks through the steps used to create a metagenomic assembly using Cerulean software loaded on an 
Amazon Web Services machine image (AMI).


# Getting started
Use the CeruleanTools AMI and attach the Pink Berries data volume. When your instance boots up, mount the volume, e.g. using the following commands to inspect the volumes and mount one to a folder called `~/data`.
```
lsblk
mkdir ~/data
sudo mount /dev/xvdf/ ~/data
```

If you make a snapshot in the right zone (e.g. us-east-1d), you can load and mount the volume directly from your instance:

```
mkdir ~/data

aws ec2 attach-volume --volume-id vol-0bdfad3677d717075 --instance-id i-0a62227ff1d1977bd --device /dev/xvdh

sudo mount /dev/xvdh ~/data
```


# Pre-processing

The relevant data for metagenomic reads originated from one sample, and were generated by two different sequencing platforms. The long reads are uncorrected PacBio reads, and the short reads are Illumina. Respectively, these files are located at:

```
~/data/metagenomes/sequence_reads/pacbio/corrected.fastq
~/data/metagenomes/sequence_reads/illumina_4pacbio/Lizzy9.fastq
```

The Pacbio file, `corrected.fastq`, is the PacBio data with all contigs stacked onto each other and error-corrected. The non-error-corrected file, `filtered-subreads.fastq`, is located within the same folder. The latter file is the raw material used to create `corrected.fastq`, and consists of PacBio reads (which were originally circular), split into pieces based on adaptor location.

# Why are all the quality scores "9" on `corrected.fastq`? 

### Deinterleaving

The short-read (Illumina) files contained paired-end reads. We need to separate the forward reads from the reverse reads.

Check out the first 6 lines of the file to see that the first two entries are corresponding reads:
```
$ head -6 Lizzy9.fastq

@HWI-M01533:129:000000000-A8CCK:1:1101:15516:1335:N:0:/1
NATATCGGCGCTCGCCAATCCGCCTTGTTGCTGTAGATCGGCAGCAAGCTGGCGGCAGCTCAAGCCGCCGACTCGCAATAGATCGGCCTCCAGCTGCACACTTTGACCGCCCTGCATATCGGGTTCTGGCAAGACCGGCGGGGTCAACGGCGAGATGGCGGGGAATGCGCCGCCCGGCGCGAAGCCCCGGGGCGAGTGCGGGGGTTCGTCGAGCAGGTACCGAGCGAGAACCAGATGGGCGGGAACCAGC
+
#>>ABABDDBBDEGGGGGGGGGGGGGHHH2GHHGGGGFHHGGGGGGHHHHHHGGCGGGGHHHHHHGGGGEGGGGGGGGGHGHHH/DCDGHHHHHHGHGHHHHHHHHHHGGGGGHHGHGHHGGGHGHGHHHHHGHHHGGGGG#############################################################################################################
@HWI-M01533:129:000000000-A8CCK:1:1101:15516:1335:N:0:/2
NTGCTTGACAGCGATGGCCTGCTGCTGGAATCTGCCGAACTCTTGGTGGATGCCACCCATGCCGCGGGCAGTGCCTCCGTCAGGTTCGGCCTGCAACCGACAACAACGACAGTGCTGGTTCTCGACCAGCTGGATCTCGATCCGTACCTGATCGACGAACCACCGCAATCGTCCCCGGGCTTCGCGTCCGGCTGCGCATTATCCGCCATCTCGCCGTTGAACCCGCCGGTCTTGCCAGAACCCGATATGC
```

The forward reads are named with a `/1` and the reverse reads with a `/2`. Using the `$` in a regular expression allows us to find lines that end with a particular character sequence, for instance `grep '/2$' Lizzy9.fastq` gets a list of all lines that end with `/2`.





